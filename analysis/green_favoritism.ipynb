{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "gf-0",
   "metadata": {},
   "source": [
    "# Green Favoritism: Birth Regions, Nightlights, and Industrial Pollution\n",
    "\n",
    "**Research question:** Do political leaders channel clean economic development to their birth regions while directing pollution-intensive industry elsewhere?\n",
    "\n",
    "**Hypothesis (Green Favoritism):**\n",
    "$$\\hat\\beta^{\\text{lights}} > 0 \\quad \\text{and} \\quad \\hat\\beta^{\\text{NO}_2} \\leq 0$$\n",
    "\n",
    "Birth regions see rising nighttime lights (economic activity) but **not** rising NO₂ (industrial pollution) — i.e., a decoupling of growth from pollution in politically favored districts.\n",
    "\n",
    "**Data:**\n",
    "- Political leaders: PLAD (Bomprezzi et al., 2025) — ADM2 birth district coding\n",
    "- Nightlights: Harmonized VIIRS (Li et al., 2020), 2018–2023\n",
    "- NO₂: TROPOMI/Sentinel-5P via Google Earth Engine, 2018–2023\n",
    "- Admin boundaries: GADM v4.1 ADM2 (built by `replication.ipynb`)\n",
    "\n",
    "> **Prerequisite:** Run `replication.ipynb` first to build the ADM2 boundary cache (`data/gadm/gadm41_adm2.gpkg`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "gf-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import zipfile\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from rasterstats import zonal_stats\n",
    "from linearmodels.panel import PanelOLS\n",
    "import ee\n",
    "\n",
    "GEE_PROJECT = \"gen-lang-client-0840443535\"\n",
    "\n",
    "ee.Authenticate()   # opens browser — only needed once\n",
    "ee.Initialize(project=GEE_PROJECT)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "ROOT      = Path(\"..\")  # project root\n",
    "DATA      = ROOT / \"data\"\n",
    "NTL_DIR   = DATA / \"nightlights\"\n",
    "PLAD_PATH = DATA / \"political leaders\" / \"PLAD_April_2024.dta\"\n",
    "\n",
    "# Years covered by TROPOMI (and the VIIRS nightlights panel built below)\n",
    "ANALYSIS_YEARS = range(2018, 2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gf-2",
   "metadata": {},
   "source": [
    "## 1. Load shared boundary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "gf-3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 47,986 ADM2 regions\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GID_0</th>\n",
       "      <th>GID_1</th>\n",
       "      <th>GID_2</th>\n",
       "      <th>NAME_0</th>\n",
       "      <th>NAME_1</th>\n",
       "      <th>NAME_2</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ATA</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Antarctica</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>MULTIPOLYGON (((-169.00626 -83.61875, -169.004...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UKR</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>Ukraine</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>MULTIPOLYGON (((30.59167 50.41236, 30.60611 50...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  GID_0 GID_1 GID_2      NAME_0 NAME_1 NAME_2  \\\n",
       "0   ATA              Antarctica                 \n",
       "1   UKR     ?     ?     Ukraine      ?      ?   \n",
       "\n",
       "                                            geometry  \n",
       "0  MULTIPOLYGON (((-169.00626 -83.61875, -169.004...  \n",
       "1  MULTIPOLYGON (((30.59167 50.41236, 30.60611 50...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GADM_DIR   = DATA / \"gadm\"\n",
    "ADM2_CACHE = GADM_DIR / \"gadm41_adm2.gpkg\"\n",
    "\n",
    "assert ADM2_CACHE.exists(), (\n",
    "    f\"ADM2 boundary cache not found at {ADM2_CACHE}.\\n\"\n",
    "    \"Run replication.ipynb first to build it.\"\n",
    ")\n",
    "\n",
    "adm2 = gpd.read_file(ADM2_CACHE)\n",
    "print(f\"Loaded {len(adm2):,} ADM2 regions\")\n",
    "adm2.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gf-4",
   "metadata": {},
   "source": [
    "## 2. Build PLAD treatment variables (2018–2023)\n",
    "\n",
    "Same pipeline as `replication.ipynb`, but the spell expansion covers 2018–2023 (TROPOMI era) instead of 1992–2013."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "gf-5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using birth region column: gid_2\n",
      "Leaders: 820  |  countries: 151\n"
     ]
    }
   ],
   "source": [
    "plad = pd.read_stata(PLAD_PATH)\n",
    "plad = plad[plad[\"foreign_leader\"] == \"0\"].copy()\n",
    "\n",
    "# Use gid_2 (ADM2 birth district) if available; fall back to gid_1\n",
    "BIRTH_GID = \"gid_2\" if \"gid_2\" in plad.columns else \"gid_1\"\n",
    "plad = plad[plad[BIRTH_GID].str.strip() != \".\"].copy()\n",
    "plad[\"startyear\"] = plad[\"startyear\"].astype(int)\n",
    "plad[\"endyear\"]   = plad[\"endyear\"].astype(int)\n",
    "plad = plad[plad[\"archigos_id\"].str.strip() != \".\"].copy()\n",
    "plad = plad.sort_values([\"gid_0\", \"startyear\"]).reset_index(drop=True)\n",
    "\n",
    "print(f\"Using birth region column: {BIRTH_GID}\")\n",
    "print(f\"Leaders: {len(plad)}  |  countries: {plad['country'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "gf-6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Birth-district × year obs: 382\n",
      "Unique leader spells:       100\n",
      "Year range in treatment:    2018–2023\n"
     ]
    }
   ],
   "source": [
    "# Fix transition-year overlap (same as replication.ipynb)\n",
    "plad_fixed = plad.copy().reset_index(drop=True)\n",
    "for gid_0, group in plad_fixed.groupby(\"gid_0\"):\n",
    "    idxs = group.index.tolist()\n",
    "    for i in range(len(idxs) - 1):\n",
    "        curr, nxt = idxs[i], idxs[i + 1]\n",
    "        if plad_fixed.loc[curr, \"endyear\"] >= plad_fixed.loc[nxt, \"startyear\"]:\n",
    "            plad_fixed.loc[curr, \"endyear\"] = plad_fixed.loc[nxt, \"startyear\"] - 1\n",
    "\n",
    "# Expand spells into birth-district × year rows for ANALYSIS_YEARS\n",
    "YEAR_MIN, YEAR_MAX = min(ANALYSIS_YEARS), max(ANALYSIS_YEARS)\n",
    "rows = []\n",
    "for idx, row in plad_fixed.iterrows():\n",
    "    for y in range(max(int(row[\"startyear\"]), YEAR_MIN),\n",
    "                   min(int(row[\"endyear\"]),   YEAR_MAX) + 1):\n",
    "        rows.append({\"GID_2\": row[BIRTH_GID], \"GID_0\": row[\"gid_0\"],\n",
    "                     \"year\": y, \"spell_id\": idx})\n",
    "\n",
    "leader_years = pd.DataFrame(rows)\n",
    "leader_years = leader_years.drop_duplicates(subset=[\"GID_2\", \"year\"])\n",
    "leader_years[\"birth_region_leader\"] = 1\n",
    "\n",
    "spell_map = (leader_years[[\"GID_0\", \"year\", \"spell_id\"]]\n",
    "             .drop_duplicates(subset=[\"GID_0\", \"year\"]))\n",
    "\n",
    "print(f\"Birth-district × year obs: {len(leader_years)}\")\n",
    "print(f\"Unique leader spells:       {spell_map['spell_id'].nunique()}\")\n",
    "print(f\"Year range in treatment:    {leader_years['year'].min()}–{leader_years['year'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gf-7",
   "metadata": {},
   "source": [
    "## 3. Nightlights panel (VIIRS, 2018–2023)\n",
    "\n",
    "The harmonized Li et al. (2020) VIIRS rasters are named `Harmonized_DN_NTL_{year}_simVIIRS.tif`.\n",
    "Download them from the [dataset page](https://doi.org/10.7910/DVN/YGIVCD) and place them in `data/nightlights/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "gf-8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing 2018... done\n",
      "  Processing 2019... done\n",
      "  Processing 2020... done\n",
      "  Processing 2021... done\n",
      "  Processing 2022... done\n",
      "  Processing 2023... done\n",
      "\n",
      "Saved VIIRS panel to ../data/nightlights_adm2_viirs_panel.parquet\n",
      "VIIRS panel: 287,916 obs | 47,986 regions | years: [np.int64(2018), np.int64(2019), np.int64(2020), np.int64(2021), np.int64(2022), np.int64(2023)]\n"
     ]
    }
   ],
   "source": [
    "VIIRS_CACHE = DATA / \"nightlights_adm2_viirs_panel.parquet\"\n",
    "\n",
    "if VIIRS_CACHE.exists():\n",
    "    print(f\"Loading cached VIIRS panel from {VIIRS_CACHE}\")\n",
    "    ntl_panel = pd.read_parquet(VIIRS_CACHE)\n",
    "else:\n",
    "    frames = []\n",
    "    for year in ANALYSIS_YEARS:\n",
    "        rpath = NTL_DIR / f\"Harmonized_DN_NTL_{year}_simVIIRS.tif\"\n",
    "        if not rpath.exists():\n",
    "            print(f\"  Skipping {year} — raster not found at {rpath}\")\n",
    "            continue\n",
    "        print(f\"  Processing {year}...\", end=\" \", flush=True)\n",
    "        stats = zonal_stats(adm2.geometry, str(rpath), stats=[\"mean\"], nodata=0)\n",
    "        frames.append(pd.DataFrame({\n",
    "            \"GID_2\":    adm2[\"GID_2\"].values,\n",
    "            \"GID_1\":    adm2[\"GID_1\"].values,\n",
    "            \"GID_0\":    adm2[\"GID_0\"].values,\n",
    "            \"year\":     year,\n",
    "            \"ntl_mean\": [s[\"mean\"] for s in stats],\n",
    "        }))\n",
    "        print(f\"done\")\n",
    "\n",
    "    assert frames, \"No VIIRS rasters found — download them to data/nightlights/ first.\"\n",
    "    ntl_panel = pd.concat(frames, ignore_index=True)\n",
    "    ntl_panel.to_parquet(VIIRS_CACHE)\n",
    "    print(f\"\\nSaved VIIRS panel to {VIIRS_CACHE}\")\n",
    "\n",
    "print(f\"VIIRS panel: {len(ntl_panel):,} obs | \"\n",
    "      f\"{ntl_panel['GID_2'].nunique():,} regions | \"\n",
    "      f\"years: {sorted(ntl_panel['year'].unique())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gf-9",
   "metadata": {},
   "source": "## 4. NO₂ data collection (TROPOMI via Google Earth Engine)\n\nWe use **TROPOMI/Sentinel-5P** tropospheric NO₂ (2018–present, ~5.5 km) aggregated to ADM2 level via GEE's `reduceRegions`.\n\n### One-time GEE setup\n1. Run the cell below to create `data/gadm/gadm41_adm2.zip` (cleaned shapefile for upload)\n2. Go to [code.earthengine.google.com](https://code.earthengine.google.com) → **Assets** → **New** → **Shape files** → upload the zip\n3. Set the asset ID to `projects/YOUR_PROJECT/assets/gadm41_adm2`\n4. Set `GEE_PROJECT` in the next cell and run the task"
  },
  {
   "cell_type": "code",
   "id": "1d7lzf9ub03",
   "source": "import shutil\nfrom shapely.geometry import box\n\nSHP_DIR = DATA / \"gadm\" / \"gadm41_adm2_shp\"\nSHP_ZIP = DATA / \"gadm\" / \"gadm41_adm2.zip\"\n\nif SHP_ZIP.exists():\n    print(f\"Shapefile zip already exists: {SHP_ZIP}  ({SHP_ZIP.stat().st_size / 1e6:.1f} MB)\")\n    print(\"Delete it and re-run this cell if you need to rebuild.\")\nelse:\n    if SHP_DIR.exists():\n        shutil.rmtree(SHP_DIR)\n\n    shp_adm2 = adm2[[\"GID_0\", \"GID_1\", \"GID_2\", \"geometry\"]].copy()\n\n    # Fix self-intersecting geometries\n    shp_adm2[\"geometry\"] = shp_adm2[\"geometry\"].buffer(0)\n\n    # Clip to valid WGS84 bounds — removes out-of-range vertices that cause GEE errors\n    valid_bounds = box(-180, -90, 180, 90)\n    shp_adm2[\"geometry\"] = shp_adm2[\"geometry\"].intersection(valid_bounds)\n\n    # Drop empty/null geometries left after clipping\n    shp_adm2 = shp_adm2[shp_adm2.geometry.notna() & ~shp_adm2.geometry.is_empty]\n\n    # Simplify to reduce vertex count (GEE limit: 1M vertices per feature)\n    shp_adm2[\"geometry\"] = shp_adm2[\"geometry\"].simplify(0.01, preserve_topology=True)\n\n    shp_adm2.to_file(SHP_DIR, driver=\"ESRI Shapefile\")\n\n    with zipfile.ZipFile(SHP_ZIP, \"w\", zipfile.ZIP_DEFLATED) as zf:\n        for f in SHP_DIR.glob(\"*\"):\n            zf.write(f, f.name)\n\n    print(f\"Features: {len(shp_adm2):,}\")\n    print(f\"Created {SHP_ZIP}  ({SHP_ZIP.stat().st_size / 1e6:.1f} MB)\")\n    print(f\"Upload this zip to GEE via the web UI.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "gf-10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GEE initialized\n"
     ]
    }
   ],
   "source": [
    "# ── Update these lines ─────────────────────────────────────────────────────\n",
    "GEE_PROJECT  = \"gen-lang-client-0840443535\"                          # ← change this\n",
    "ASSET_ID     = f\"projects/{GEE_PROJECT}/assets/gadm41_adm2\"\n",
    "DRIVE_FOLDER = \"GreenFavoritism\"\n",
    "# ───────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "NO2_CSV         = DATA / \"no2_adm2_annual.csv\"\n",
    "NO2_PANEL_CACHE = DATA / \"no2_adm2_panel.parquet\"\n",
    "\n",
    "ee.Initialize(project=GEE_PROJECT)\n",
    "print(\"GEE initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "gf-11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task submitted: P577VLAFHFYJM63G57LM7LS3\n",
      "Monitor: https://code.earthengine.google.com/tasks\n",
      "When done, download 'no2_adm2_annual.csv' from Google Drive (GreenFavoritism/)\n",
      "to: ../data/\n"
     ]
    }
   ],
   "source": [
    "# Submit GEE task: annual mean TROPOMI NO₂ per ADM2 district.\n",
    "# Skips if data is already downloaded.\n",
    "\n",
    "if NO2_CSV.exists() or NO2_PANEL_CACHE.exists():\n",
    "    print(\"NO₂ data already present — skipping GEE task.\")\n",
    "else:\n",
    "    adm2_fc = ee.FeatureCollection(ASSET_ID)\n",
    "    s5p = (\n",
    "        ee.ImageCollection(\"COPERNICUS/S5P/OFFL/L3_NO2\")\n",
    "        .select(\"tropospheric_NO2_column_number_density\")\n",
    "    )\n",
    "\n",
    "    def annual_stats(year):\n",
    "        year  = ee.Number(year).toInt()\n",
    "        start = ee.Date.fromYMD(year, 1, 1)\n",
    "        end   = ee.Date.fromYMD(year.add(1), 1, 1)\n",
    "        img   = s5p.filterDate(start, end).mean()\n",
    "        stats = img.reduceRegions(\n",
    "            collection=adm2_fc,\n",
    "            reducer=ee.Reducer.mean().setOutputs([\"no2\"]),\n",
    "            scale=5500,\n",
    "            crs=\"EPSG:4326\",\n",
    "        )\n",
    "        return stats.map(lambda f: f.set(\"year\", year))\n",
    "\n",
    "    all_fc = ee.FeatureCollection(\n",
    "        ee.List(list(ANALYSIS_YEARS)).map(annual_stats)\n",
    "    ).flatten()\n",
    "\n",
    "    task = ee.batch.Export.table.toDrive(\n",
    "        collection=all_fc,\n",
    "        description=\"NO2_ADM2_annual_2018_2023\",\n",
    "        folder=DRIVE_FOLDER,\n",
    "        fileNamePrefix=\"no2_adm2_annual\",\n",
    "        fileFormat=\"CSV\",\n",
    "        selectors=[\"GID_0\", \"GID_2\", \"year\", \"no2\"],\n",
    "    )\n",
    "    task.start()\n",
    "    print(f\"Task submitted: {task.id}\")\n",
    "    print(f\"Monitor: https://code.earthengine.google.com/tasks\")\n",
    "    print(f\"When done, download 'no2_adm2_annual.csv' from Google Drive ({DRIVE_FOLDER}/)\")\n",
    "    print(f\"to: {DATA}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gf-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load NO₂ panel from downloaded CSV (run after GEE task completes)\n",
    "\n",
    "if NO2_PANEL_CACHE.exists():\n",
    "    print(f\"Loading cached NO₂ panel from {NO2_PANEL_CACHE}\")\n",
    "    no2_panel = pd.read_parquet(NO2_PANEL_CACHE)\n",
    "else:\n",
    "    assert NO2_CSV.exists(), (\n",
    "        f\"NO₂ CSV not found at {NO2_CSV}.\\n\"\n",
    "        f\"Complete the GEE task above, then download 'no2_adm2_annual.csv'\\n\"\n",
    "        f\"from Google Drive ({DRIVE_FOLDER}/) into {DATA}/\"\n",
    "    )\n",
    "    no2_panel = pd.read_csv(NO2_CSV)\n",
    "    no2_panel = no2_panel.rename(columns={\"no2\": \"no2_mean\"})\n",
    "    no2_panel = no2_panel.dropna(subset=[\"no2_mean\"])\n",
    "    no2_panel = no2_panel[no2_panel[\"no2_mean\"] >= 0]   # drop fill values\n",
    "    no2_panel[\"no2_mean\"] = no2_panel[\"no2_mean\"] * 1e6  # mol/m² → µmol/m²\n",
    "    no2_panel.to_parquet(NO2_PANEL_CACHE)\n",
    "    print(f\"Saved NO₂ panel to {NO2_PANEL_CACHE}\")\n",
    "\n",
    "print(f\"NO₂ panel: {len(no2_panel):,} obs | \"\n",
    "      f\"{no2_panel['GID_2'].nunique():,} regions | \"\n",
    "      f\"years: {sorted(no2_panel['year'].unique())}\")\n",
    "no2_panel.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gf-13",
   "metadata": {},
   "source": [
    "## 5. Build joint panel and run Green Favoritism regressions\n",
    "\n",
    "Merge VIIRS nightlights + TROPOMI NO₂ + PLAD treatment for 2018–2023, then run:\n",
    "\n",
    "$$Y_{it} = \\beta \\cdot \\text{BirthRegion}_{it} + \\alpha_i + \\gamma_{ct} + \\varepsilon_{it}$$\n",
    "\n",
    "for $Y \\in \\{\\ln(\\text{lights}), \\ln(\\text{NO}_2)\\}$ side by side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gf-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge nightlights + NO₂ + treatment\n",
    "joint = ntl_panel.merge(no2_panel[[\"GID_2\", \"year\", \"no2_mean\"]], on=[\"GID_2\", \"year\"], how=\"inner\")\n",
    "joint = joint.merge(leader_years[[\"GID_2\", \"year\", \"birth_region_leader\"]], on=[\"GID_2\", \"year\"], how=\"left\")\n",
    "joint[\"birth_region_leader\"] = joint[\"birth_region_leader\"].fillna(0).astype(int)\n",
    "joint = joint.merge(spell_map[[\"GID_0\", \"year\", \"spell_id\"]], on=[\"GID_0\", \"year\"], how=\"left\")\n",
    "joint[\"spell_id\"] = joint[\"spell_id\"].fillna(\n",
    "    joint[\"GID_0\"] + \"_\" + joint[\"year\"].astype(str) + \"_noleader\"\n",
    ").astype(str)\n",
    "\n",
    "joint = joint.sort_values([\"GID_2\", \"year\"])\n",
    "joint[\"brl_lag1\"] = joint.groupby(\"GID_2\")[\"birth_region_leader\"].shift(1).fillna(0).astype(int)\n",
    "\n",
    "joint[\"ln_ntl\"]       = np.log(joint[\"ntl_mean\"] + 0.01)\n",
    "joint[\"ln_no2\"]       = np.log(joint[\"no2_mean\"] + 0.01)\n",
    "joint[\"country_year\"] = joint[\"GID_0\"] + \"_\" + joint[\"year\"].astype(str)\n",
    "joint = joint.dropna(subset=[\"ntl_mean\", \"no2_mean\"])\n",
    "\n",
    "print(f\"Joint panel: {len(joint):,} obs | {joint['GID_2'].nunique():,} regions | \"\n",
    "      f\"years: {sorted(joint['year'].unique())}\")\n",
    "print(f\"Treated obs (birth_region_leader=1): {joint['birth_region_leader'].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gf-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Green Favoritism regressions: lights vs NO₂, Lag 0 and Lag 1\n",
    "# FE: ADM2 region + country×year  |  Clustering: leader-period\n",
    "\n",
    "joint_idx = joint.set_index([\"GID_2\", \"year\"])\n",
    "\n",
    "specs    = [(\"Lag 0\", \"birth_region_leader\"), (\"Lag 1\", \"brl_lag1\")]\n",
    "outcomes = [(\"ln_ntl\", \"log(Nightlights)\"), (\"ln_no2\", \"log(NO₂)\")]\n",
    "\n",
    "rows = []\n",
    "for lag_label, var in specs:\n",
    "    for outcome_col, outcome_label in outcomes:\n",
    "        model = PanelOLS.from_formula(\n",
    "            f\"{outcome_col} ~ {var} + EntityEffects\",\n",
    "            data=joint_idx,\n",
    "            other_effects=joint_idx[\"country_year\"],\n",
    "            drop_absorbed=True,\n",
    "        )\n",
    "        res   = model.fit(cov_type=\"clustered\", clusters=joint_idx[\"spell_id\"])\n",
    "        coef  = res.params[var]\n",
    "        se    = res.std_errors[var]\n",
    "        pval  = res.pvalues[var]\n",
    "        stars = \"***\" if pval < 0.01 else \"**\" if pval < 0.05 else \"*\" if pval < 0.1 else \"\"\n",
    "        rows.append({\n",
    "            \"Spec\":    lag_label,\n",
    "            \"Outcome\": outcome_label,\n",
    "            \"Coeff\":   f\"{coef:.4f}{stars}\",\n",
    "            \"SE\":      f\"({se:.4f})\",\n",
    "            \"p\":       f\"{pval:.3f}\",\n",
    "            \"N\":       f\"{res.nobs:,}\",\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(rows).set_index([\"Spec\", \"Outcome\"])\n",
    "print(\"Green Favoritism test\")\n",
    "print(\"FE: Region (ADM2) + Country×Year  |  Clustering: Leader-period\\n\")\n",
    "print(results_df.to_string())\n",
    "print(\"\\nSignificance: *** p<0.01, ** p<0.05, * p<0.1\")\n",
    "print(\"\\nGreen Favoritism = lights coeff > 0  AND  NO₂ coeff ≤ 0\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}