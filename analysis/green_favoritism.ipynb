{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "gf-0",
   "metadata": {},
   "source": [
    "# Green Favoritism: Birth Regions, Nightlights, and Industrial Pollution\n",
    "\n",
    "**Research question:** Do political leaders channel clean economic development to their birth regions while directing pollution-intensive industry elsewhere?\n",
    "\n",
    "**Hypothesis (Green Favoritism):**\n",
    "$$\\hat\\beta^{\\text{lights}} > 0 \\quad \\text{and} \\quad \\hat\\beta^{\\text{NO}_2} \\leq 0$$\n",
    "\n",
    "Birth regions see rising nighttime lights (economic activity) but **not** rising NO₂ (industrial pollution) — i.e., a decoupling of growth from pollution in politically favored districts.\n",
    "\n",
    "**Data:**\n",
    "- Political leaders: PLAD (Bomprezzi et al., 2025) — ADM2 birth district coding\n",
    "- Nightlights: Harmonized VIIRS (Li et al., 2020), 2018–2023\n",
    "- NO₂: TROPOMI/Sentinel-5P via Google Earth Engine, 2018–2023\n",
    "- Admin boundaries: GADM v4.1 ADM2 (built by `replication.ipynb`)\n",
    "\n",
    "> **Prerequisite:** Run `replication.ipynb` first to build the ADM2 boundary cache (`data/gadm/gadm41_adm2.gpkg`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gf-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import zipfile\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from rasterstats import zonal_stats\n",
    "from linearmodels.panel import PanelOLS\n",
    "import ee\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "ROOT      = Path(\"..\")  # project root\n",
    "DATA      = ROOT / \"data\"\n",
    "NTL_DIR   = DATA / \"nightlights\"\n",
    "PLAD_PATH = DATA / \"political leaders\" / \"PLAD_April_2024.dta\"\n",
    "\n",
    "# Years covered by TROPOMI (and the VIIRS nightlights panel built below)\n",
    "ANALYSIS_YEARS = range(2018, 2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gf-2",
   "metadata": {},
   "source": [
    "## 1. Load shared boundary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gf-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "GADM_DIR   = DATA / \"gadm\"\n",
    "ADM2_CACHE = GADM_DIR / \"gadm41_adm2.gpkg\"\n",
    "\n",
    "assert ADM2_CACHE.exists(), (\n",
    "    f\"ADM2 boundary cache not found at {ADM2_CACHE}.\\n\"\n",
    "    \"Run replication.ipynb first to build it.\"\n",
    ")\n",
    "\n",
    "adm2 = gpd.read_file(ADM2_CACHE)\n",
    "print(f\"Loaded {len(adm2):,} ADM2 regions\")\n",
    "adm2.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gf-4",
   "metadata": {},
   "source": [
    "## 2. Build PLAD treatment variables (2018–2023)\n",
    "\n",
    "Same pipeline as `replication.ipynb`, but the spell expansion covers 2018–2023 (TROPOMI era) instead of 1992–2013."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gf-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plad = pd.read_stata(PLAD_PATH)\n",
    "plad = plad[plad[\"foreign_leader\"] == \"0\"].copy()\n",
    "\n",
    "# Use gid_2 (ADM2 birth district) if available; fall back to gid_1\n",
    "BIRTH_GID = \"gid_2\" if \"gid_2\" in plad.columns else \"gid_1\"\n",
    "plad = plad[plad[BIRTH_GID].str.strip() != \".\"].copy()\n",
    "plad[\"startyear\"] = plad[\"startyear\"].astype(int)\n",
    "plad[\"endyear\"]   = plad[\"endyear\"].astype(int)\n",
    "plad = plad[plad[\"archigos_id\"].str.strip() != \".\"].copy()\n",
    "plad = plad.sort_values([\"gid_0\", \"startyear\"]).reset_index(drop=True)\n",
    "\n",
    "print(f\"Using birth region column: {BIRTH_GID}\")\n",
    "print(f\"Leaders: {len(plad)}  |  countries: {plad['country'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gf-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix transition-year overlap (same as replication.ipynb)\n",
    "plad_fixed = plad.copy().reset_index(drop=True)\n",
    "for gid_0, group in plad_fixed.groupby(\"gid_0\"):\n",
    "    idxs = group.index.tolist()\n",
    "    for i in range(len(idxs) - 1):\n",
    "        curr, nxt = idxs[i], idxs[i + 1]\n",
    "        if plad_fixed.loc[curr, \"endyear\"] >= plad_fixed.loc[nxt, \"startyear\"]:\n",
    "            plad_fixed.loc[curr, \"endyear\"] = plad_fixed.loc[nxt, \"startyear\"] - 1\n",
    "\n",
    "# Expand spells into birth-district × year rows for ANALYSIS_YEARS\n",
    "YEAR_MIN, YEAR_MAX = min(ANALYSIS_YEARS), max(ANALYSIS_YEARS)\n",
    "rows = []\n",
    "for idx, row in plad_fixed.iterrows():\n",
    "    for y in range(max(int(row[\"startyear\"]), YEAR_MIN),\n",
    "                   min(int(row[\"endyear\"]),   YEAR_MAX) + 1):\n",
    "        rows.append({\"GID_2\": row[BIRTH_GID], \"GID_0\": row[\"gid_0\"],\n",
    "                     \"year\": y, \"spell_id\": idx})\n",
    "\n",
    "leader_years = pd.DataFrame(rows)\n",
    "leader_years = leader_years.drop_duplicates(subset=[\"GID_2\", \"year\"])\n",
    "leader_years[\"birth_region_leader\"] = 1\n",
    "\n",
    "spell_map = (leader_years[[\"GID_0\", \"year\", \"spell_id\"]]\n",
    "             .drop_duplicates(subset=[\"GID_0\", \"year\"]))\n",
    "\n",
    "print(f\"Birth-district × year obs: {len(leader_years)}\")\n",
    "print(f\"Unique leader spells:       {spell_map['spell_id'].nunique()}\")\n",
    "print(f\"Year range in treatment:    {leader_years['year'].min()}–{leader_years['year'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gf-7",
   "metadata": {},
   "source": [
    "## 3. Nightlights panel (VIIRS, 2018–2023)\n",
    "\n",
    "The harmonized Li et al. (2020) VIIRS rasters are named `Harmonized_DN_NTL_{year}_simVIIRS.tif`.\n",
    "Download them from the [dataset page](https://doi.org/10.7910/DVN/YGIVCD) and place them in `data/nightlights/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gf-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "VIIRS_CACHE = DATA / \"nightlights_adm2_viirs_panel.parquet\"\n",
    "\n",
    "if VIIRS_CACHE.exists():\n",
    "    print(f\"Loading cached VIIRS panel from {VIIRS_CACHE}\")\n",
    "    ntl_panel = pd.read_parquet(VIIRS_CACHE)\n",
    "else:\n",
    "    frames = []\n",
    "    for year in ANALYSIS_YEARS:\n",
    "        rpath = NTL_DIR / f\"Harmonized_DN_NTL_{year}_simVIIRS.tif\"\n",
    "        if not rpath.exists():\n",
    "            print(f\"  Skipping {year} — raster not found at {rpath}\")\n",
    "            continue\n",
    "        print(f\"  Processing {year}...\", end=\" \", flush=True)\n",
    "        stats = zonal_stats(adm2.geometry, str(rpath), stats=[\"mean\"], nodata=0)\n",
    "        frames.append(pd.DataFrame({\n",
    "            \"GID_2\":    adm2[\"GID_2\"].values,\n",
    "            \"GID_1\":    adm2[\"GID_1\"].values,\n",
    "            \"GID_0\":    adm2[\"GID_0\"].values,\n",
    "            \"year\":     year,\n",
    "            \"ntl_mean\": [s[\"mean\"] for s in stats],\n",
    "        }))\n",
    "        print(f\"done\")\n",
    "\n",
    "    assert frames, \"No VIIRS rasters found — download them to data/nightlights/ first.\"\n",
    "    ntl_panel = pd.concat(frames, ignore_index=True)\n",
    "    ntl_panel.to_parquet(VIIRS_CACHE)\n",
    "    print(f\"\\nSaved VIIRS panel to {VIIRS_CACHE}\")\n",
    "\n",
    "print(f\"VIIRS panel: {len(ntl_panel):,} obs | \"\n",
    "      f\"{ntl_panel['GID_2'].nunique():,} regions | \"\n",
    "      f\"years: {sorted(ntl_panel['year'].unique())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gf-9",
   "metadata": {},
   "source": [
    "## 4. NO₂ data collection (TROPOMI via Google Earth Engine)\n",
    "\n",
    "We use **TROPOMI/Sentinel-5P** tropospheric NO₂ (2018–present, ~5.5 km) aggregated to ADM2 level via GEE's `reduceRegions`.\n",
    "\n",
    "### One-time GEE setup (run in terminal)\n",
    "\n",
    "```bash\n",
    "# 1. Authenticate\n",
    "earthengine authenticate\n",
    "\n",
    "# 2. Upload ADM2 boundaries as a GEE asset  (replace YOUR_PROJECT)\n",
    "earthengine upload table \\\n",
    "    --asset_id=projects/YOUR_PROJECT/assets/gadm41_adm2 \\\n",
    "    ../data/gadm/gadm41_adm2.gpkg\n",
    "```\n",
    "\n",
    "Then set `GEE_PROJECT` in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gf-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Update these lines ─────────────────────────────────────────────────────\n",
    "GEE_PROJECT  = \"your-gee-project-id\"                          # ← change this\n",
    "ASSET_ID     = f\"projects/{GEE_PROJECT}/assets/gadm41_adm2\"\n",
    "DRIVE_FOLDER = \"GreenFavoritism\"\n",
    "# ───────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "NO2_CSV         = DATA / \"no2_adm2_annual.csv\"\n",
    "NO2_PANEL_CACHE = DATA / \"no2_adm2_panel.parquet\"\n",
    "\n",
    "ee.Initialize(project=GEE_PROJECT)\n",
    "print(\"GEE initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gf-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit GEE task: annual mean TROPOMI NO₂ per ADM2 district.\n",
    "# Skips if data is already downloaded.\n",
    "\n",
    "if NO2_CSV.exists() or NO2_PANEL_CACHE.exists():\n",
    "    print(\"NO₂ data already present — skipping GEE task.\")\n",
    "else:\n",
    "    adm2_fc = ee.FeatureCollection(ASSET_ID)\n",
    "    s5p = (\n",
    "        ee.ImageCollection(\"COPERNICUS/S5P/OFFL/L3_NO2\")\n",
    "        .select(\"tropospheric_NO2_column_number_density\")\n",
    "    )\n",
    "\n",
    "    def annual_stats(year):\n",
    "        year  = ee.Number(year).toInt()\n",
    "        start = ee.Date.fromYMD(year, 1, 1)\n",
    "        end   = ee.Date.fromYMD(year.add(1), 1, 1)\n",
    "        img   = s5p.filterDate(start, end).mean()\n",
    "        stats = img.reduceRegions(\n",
    "            collection=adm2_fc,\n",
    "            reducer=ee.Reducer.mean().setOutputs([\"no2\"]),\n",
    "            scale=5500,\n",
    "            crs=\"EPSG:4326\",\n",
    "        )\n",
    "        return stats.map(lambda f: f.set(\"year\", year))\n",
    "\n",
    "    all_fc = ee.FeatureCollection(\n",
    "        ee.List(list(ANALYSIS_YEARS)).map(annual_stats)\n",
    "    ).flatten()\n",
    "\n",
    "    task = ee.batch.Export.table.toDrive(\n",
    "        collection=all_fc,\n",
    "        description=\"NO2_ADM2_annual_2018_2023\",\n",
    "        folder=DRIVE_FOLDER,\n",
    "        fileNamePrefix=\"no2_adm2_annual\",\n",
    "        fileFormat=\"CSV\",\n",
    "        selectors=[\"GID_0\", \"GID_2\", \"year\", \"no2\"],\n",
    "    )\n",
    "    task.start()\n",
    "    print(f\"Task submitted: {task.id}\")\n",
    "    print(f\"Monitor: https://code.earthengine.google.com/tasks\")\n",
    "    print(f\"When done, download 'no2_adm2_annual.csv' from Google Drive ({DRIVE_FOLDER}/)\")\n",
    "    print(f\"to: {DATA}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gf-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load NO₂ panel from downloaded CSV (run after GEE task completes)\n",
    "\n",
    "if NO2_PANEL_CACHE.exists():\n",
    "    print(f\"Loading cached NO₂ panel from {NO2_PANEL_CACHE}\")\n",
    "    no2_panel = pd.read_parquet(NO2_PANEL_CACHE)\n",
    "else:\n",
    "    assert NO2_CSV.exists(), (\n",
    "        f\"NO₂ CSV not found at {NO2_CSV}.\\n\"\n",
    "        f\"Complete the GEE task above, then download 'no2_adm2_annual.csv'\\n\"\n",
    "        f\"from Google Drive ({DRIVE_FOLDER}/) into {DATA}/\"\n",
    "    )\n",
    "    no2_panel = pd.read_csv(NO2_CSV)\n",
    "    no2_panel = no2_panel.rename(columns={\"no2\": \"no2_mean\"})\n",
    "    no2_panel = no2_panel.dropna(subset=[\"no2_mean\"])\n",
    "    no2_panel = no2_panel[no2_panel[\"no2_mean\"] >= 0]   # drop fill values\n",
    "    no2_panel[\"no2_mean\"] = no2_panel[\"no2_mean\"] * 1e6  # mol/m² → µmol/m²\n",
    "    no2_panel.to_parquet(NO2_PANEL_CACHE)\n",
    "    print(f\"Saved NO₂ panel to {NO2_PANEL_CACHE}\")\n",
    "\n",
    "print(f\"NO₂ panel: {len(no2_panel):,} obs | \"\n",
    "      f\"{no2_panel['GID_2'].nunique():,} regions | \"\n",
    "      f\"years: {sorted(no2_panel['year'].unique())}\")\n",
    "no2_panel.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gf-13",
   "metadata": {},
   "source": [
    "## 5. Build joint panel and run Green Favoritism regressions\n",
    "\n",
    "Merge VIIRS nightlights + TROPOMI NO₂ + PLAD treatment for 2018–2023, then run:\n",
    "\n",
    "$$Y_{it} = \\beta \\cdot \\text{BirthRegion}_{it} + \\alpha_i + \\gamma_{ct} + \\varepsilon_{it}$$\n",
    "\n",
    "for $Y \\in \\{\\ln(\\text{lights}), \\ln(\\text{NO}_2)\\}$ side by side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gf-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge nightlights + NO₂ + treatment\n",
    "joint = ntl_panel.merge(no2_panel[[\"GID_2\", \"year\", \"no2_mean\"]], on=[\"GID_2\", \"year\"], how=\"inner\")\n",
    "joint = joint.merge(leader_years[[\"GID_2\", \"year\", \"birth_region_leader\"]], on=[\"GID_2\", \"year\"], how=\"left\")\n",
    "joint[\"birth_region_leader\"] = joint[\"birth_region_leader\"].fillna(0).astype(int)\n",
    "joint = joint.merge(spell_map[[\"GID_0\", \"year\", \"spell_id\"]], on=[\"GID_0\", \"year\"], how=\"left\")\n",
    "joint[\"spell_id\"] = joint[\"spell_id\"].fillna(\n",
    "    joint[\"GID_0\"] + \"_\" + joint[\"year\"].astype(str) + \"_noleader\"\n",
    ").astype(str)\n",
    "\n",
    "joint = joint.sort_values([\"GID_2\", \"year\"])\n",
    "joint[\"brl_lag1\"] = joint.groupby(\"GID_2\")[\"birth_region_leader\"].shift(1).fillna(0).astype(int)\n",
    "\n",
    "joint[\"ln_ntl\"]       = np.log(joint[\"ntl_mean\"] + 0.01)\n",
    "joint[\"ln_no2\"]       = np.log(joint[\"no2_mean\"] + 0.01)\n",
    "joint[\"country_year\"] = joint[\"GID_0\"] + \"_\" + joint[\"year\"].astype(str)\n",
    "joint = joint.dropna(subset=[\"ntl_mean\", \"no2_mean\"])\n",
    "\n",
    "print(f\"Joint panel: {len(joint):,} obs | {joint['GID_2'].nunique():,} regions | \"\n",
    "      f\"years: {sorted(joint['year'].unique())}\")\n",
    "print(f\"Treated obs (birth_region_leader=1): {joint['birth_region_leader'].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gf-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Green Favoritism regressions: lights vs NO₂, Lag 0 and Lag 1\n",
    "# FE: ADM2 region + country×year  |  Clustering: leader-period\n",
    "\n",
    "joint_idx = joint.set_index([\"GID_2\", \"year\"])\n",
    "\n",
    "specs    = [(\"Lag 0\", \"birth_region_leader\"), (\"Lag 1\", \"brl_lag1\")]\n",
    "outcomes = [(\"ln_ntl\", \"log(Nightlights)\"), (\"ln_no2\", \"log(NO₂)\")]\n",
    "\n",
    "rows = []\n",
    "for lag_label, var in specs:\n",
    "    for outcome_col, outcome_label in outcomes:\n",
    "        model = PanelOLS.from_formula(\n",
    "            f\"{outcome_col} ~ {var} + EntityEffects\",\n",
    "            data=joint_idx,\n",
    "            other_effects=joint_idx[\"country_year\"],\n",
    "            drop_absorbed=True,\n",
    "        )\n",
    "        res   = model.fit(cov_type=\"clustered\", clusters=joint_idx[\"spell_id\"])\n",
    "        coef  = res.params[var]\n",
    "        se    = res.std_errors[var]\n",
    "        pval  = res.pvalues[var]\n",
    "        stars = \"***\" if pval < 0.01 else \"**\" if pval < 0.05 else \"*\" if pval < 0.1 else \"\"\n",
    "        rows.append({\n",
    "            \"Spec\":    lag_label,\n",
    "            \"Outcome\": outcome_label,\n",
    "            \"Coeff\":   f\"{coef:.4f}{stars}\",\n",
    "            \"SE\":      f\"({se:.4f})\",\n",
    "            \"p\":       f\"{pval:.3f}\",\n",
    "            \"N\":       f\"{res.nobs:,}\",\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(rows).set_index([\"Spec\", \"Outcome\"])\n",
    "print(\"Green Favoritism test\")\n",
    "print(\"FE: Region (ADM2) + Country×Year  |  Clustering: Leader-period\\n\")\n",
    "print(results_df.to_string())\n",
    "print(\"\\nSignificance: *** p<0.01, ** p<0.05, * p<0.1\")\n",
    "print(\"\\nGreen Favoritism = lights coeff > 0  AND  NO₂ coeff ≤ 0\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
